{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft and Experiment Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First impression\n",
    "    * What is my chosen paper to read?\n",
    "    (The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks)\n",
    "    * What type of the main contribution the paper has made?\n",
    "    (The study of probabilistic Inference.)\n",
    "        - A theory or proposition (revealing something, from unknown to known)\n",
    "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
    "\n",
    "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
    "    (It is to find a method of probabilistic Inference.)\n",
    "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
    "    (For the reason that I have learned the subject of Stochastic Processes and Application. After reading the introduction, I found it is quite similar.) \n",
    "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
    "(NP-hard    3SAT)\n",
    "3. (During the next 7 days) Re-consider the central problem of the paper.\n",
    "(Using Bayesian Belief Networks to prove that probabilistic Inference is NP-hard, which means that it is difficult to find a general, accurate and effective algorithm.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Report on \"The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website: https://github.com/Jiaqi-liu123/UTS_ML2019_13058971/blob/master/A1_Report13058971.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This research was not intended to publish new algorithms, but to negate the generality of probabilistic inference algorithms by using computer. The author proved that probabilistic inference using general belief networks is NP-hard. So the main question of this article was to explore whether a general algorithm for probabilistic inference can be found easily by computer. To prove this, the author used the Bayesian belief networks to prove. According to the analysis, the writer found that it is difficult to find a general, accurate and effective algorithm in the real world. Furthermore, based on the real situation, the author showed out some algorithm ideas about how to do probabilistic inference.\n",
    "\n",
    "In the process of proof, the author first introduces belief-network structure. Then the probabilistic inference problem is brought into the 3SAT. Finally, it is inferred from 3SAT that probabilistic inference using general belief networks is NP-hard. In particular, probabilistic inference using multiply connected belief networks with uninstantiated variables is NP-hard. NP-hard shows that in practical application, it is difficult to get very effective algorithms for such problems. So in reality, people seldom find such an algorithm.\n",
    "\n",
    "However, in real life, such problems will be encountered, such as medical aspects. The author gives three inexact methods to solve this problem. They are average-case, special-case, and approximation algorithms. The first two are to stop looking for general algorithms. They calculate different algorithms according to different special case or average situations. Then the prediction analysis is carried out according to these algorithms. For example, according to the linear time data analysis or clustering data before probabilistic inference. In addition, approximation algorithms are dedicated to find imprecise boundaries rather than precise inferences.\n",
    "\n",
    "Generally, in the aspect of probabilistic inference, this paper proves that it is inefficient to find a general and accurate algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innovation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The innovation of this research is to prove Probabilistic Inference is NP-hard in mathematics. In addition, in the discussion, the author also cited three methods that can be used for Probabilistic Inference analysis. But he did not give an in-depth introduction. Even the example analysis is rare.\n",
    "\n",
    "Combined with the release date of the study, 1990 was a period in which data mining was just beginning to develop(Masashi M. 2015). Although there were computers, C language and database at this time. However, there was no particular development in data analysis. In addition, in 1880, mathematical data analysis began to develop. This is why this study favors mathematical proof rather than analysis based on factors such as computer complexity. To a certain extent, the author's other innovation is not to find a mathematical model that is universally stable. Instead, he proposed using a computer for a special case analysis.\n",
    "\n",
    "In the case of example analysis, most of the authors use medical examples. This is because the author is from the Medical Computer Science Group of Stanford University.\n",
    "\n",
    "In addition, the author's final example shows that his ideas are similar to some of the current methods of data analysis. Special case, such as decision tree and SVM, nowadays always is used to analyze. At the moment, data analysis has moved away from mathematical problems. These algorithms are now more used for computer analysis than pure mathematical inference. Although this algorithm was proposed in the early years. Avram Sidi (1982) analyzed the Richardson extrapolation process using the special case. But it was still using mathematical inference rather than focusing on the computer. So another innovation of this paper proposes is to apply it to computers part.\n",
    "\n",
    "In addition, the authors proposed that the predicted result is a range rather than an exact value. This is used in the current time series. The predicted result of the ARIMA model is the possible range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data analysis research, this paper is unqualified. Because although the article proposes an idea that uses case data for analysis, it does not have any real data to demonstrate. This study is more like a mathematical paper than a data analysis paper. There is a lot of mathematical inferences in the text instead of using actual data to prove it. From the beginning of the interpretation of NP-hard to 3SAT, the text is all mathematical inference. There was no data to prove until the end. However, in mathematics, the author only analyzes the two cases where the possibilities are true and false. This is also a bit less rigorous. Of course, if only two cases can not get an accurate algorithm, a variety of nodes are even less likely. But the author did not mention the situation of a variety of probabilities. This is a disadvantage for mathematical papers.\n",
    "\n",
    "In addition, in the latter examples, the author did not prove it with real data. He even said that these algorithms have medical applications rather than specific examples. Although the readers can understand the real application of these algorithms, it must be said that this is also a shortcoming of this article.\n",
    "\n",
    "In summary, although the author's point of view is very useful, the author's argument is still somewhat flawed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application and X-factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper mainly carries out the proof analysis in the field of mathematics. But the actual results have been widely used in data analysis. Because there are many places where these two areas overlap, the research projects and fields are still very consistent. In addition, the author also mentioned a little medical knowledge. As for other areas, this can be applied to many places related to data analysis. Such as computer and finance. Probably because of time constraints, this study did not introduce too much computer content. But in fact, these algorithms can be applied to computers. On the financial side, many algorithms can also be used to predict the company's situation and conduct data mining.\n",
    "\n",
    "More research can focus on practical testing. For example, calculate the prediction time of a group of real data. Because of the limitation of science and technology, it was difficult for computers to complete probability inference at that time. But the technology is developing. We can continue to analyze how much time it will take to complete the probability inference. Therefore, this study is sufficient for discussion now. In addition, it can even generate new research directions. Using current technology to study whether it can reduce the computational burden of computers and complete probability inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using bayesian belief net works, the author proves that probabilistic inference is hard to finish for the reason of computational burden. From a mathematical point of view, the quality and quality of this article are also useful. The author's mathematical argument is also reasonable. But from the point of view of computer, there are some limitations.\n",
    "\n",
    "Firstly, there is a lack of practical experiments in this study. Then real data can be used to predict. How long will it take the computer to complete the probability inference? And analyze its accuracy. This will make the research more complete and credible. In addition, it can better clearly point out the technical defects. It can be used as a reference for future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "COO90:Gregory F., 1990, 'The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks', Artificial Intelligence, pp. 393-405.\n",
    "\n",
    "[History][1]: Masashi M., 2015, 'A Brief History of Data Analysis', <https://www.flydata.com/blog/a-brief-history-of-data-analysis/>.\n",
    "\n",
    "[Special Case][2]: Avram S., 1982, 'An Algorithm for a Special Case of a Generalization of the Richardson Extrapolation Process', Numer Math, pp. 299-307.\n",
    "\n",
    "[1]:https://www.flydata.com/blog/a-brief-history-of-data-analysis/\n",
    "\n",
    "[2]:https://pdfs.semanticscholar.org/e66f/65824808ec97adab5fa4718a977c6929fd50.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
